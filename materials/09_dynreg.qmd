---
title: "Time Series Analysis & Forecasting Using R"
subtitle: "9. Dynamic regression"
format:
  beamer:
    pdf-engine: pdflatex
    aspectratio: 169
    fontsize: "14pt,t"
    section-titles: false
    knitr:
      opts_chunk:
        dev: "cairo_pdf"
    fig-width: 7.5
    fig-height: 3.5
    include-in-header: header.tex
    keep-tex: false
---

## Outline

\vspace*{0.7cm}\tableofcontents


```{r}
#| label: setup
#| include: false
#| cache: false
source("setup.R")
vic_elec_daily <- vic_elec |>
  filter(year(Time) == 2014) |>
  index_by(Date = date(Time)) |>
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) |>
  mutate(Day_Type = case_when(
    Holiday ~ "Holiday",
    wday(Date) %in% 2:6 ~ "Weekday",
    TRUE ~ "Weekend"
  ))
```

<!-- # Notice: Material planned to change -->

<!-- ## Notice: Material planned to change -->

<!-- This material is planned to be updated to better align with the training needs of the Department of Education.  -->

<!-- In particular, the new material will be more focused on: -->

<!-- * the use of policy in models, -->
<!-- * forecasting with different scenarios. -->

# Regression with ARIMA errors

## Time series regression

\fontsize{13}{15}\sf

:::{.callout-note}
## Regression models

$$
y_t = \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \varepsilon_t,
$$
:::

  * $y_t$ modeled as function of $k$ explanatory variables
  * In regression, we assume that $\varepsilon_t$ is white noise.
  
. . .
  
Specify this model with `TSLM()`.

Much like `lm()`, regressors are specified on the formula's right.

## Regression with ARIMA errors

:::{.callout-note}
## RegARIMA models

\begin{align*}
  y_t &= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\\
      \eta_t &\sim \text{ARIMA}
\end{align*}
:::

  * Residuals are from ARIMA model.
  * Estimate model in one step using MLE
  * Select model with lowest AICc value.
  
Simply add regression terms to the `ARIMA()` formula's right.

# Some useful predictors

## Some useful predictors

:::{.callout-note}
## Linear trend

The time index is an effective predictor for trends.

It can be added to models as a regressor with `trend()`.
:::

. . .

:::{.callout-tip}
## Piecewise linear trend

Trends often change over time.

We can add changepoints in the trend with 

`trend(knots = <times>)`.
:::

## Some useful predictors

:::{.callout-note}
## Dummy variables

Identify categories of observations with $\{0,1\}$ indicators.

Useful for public holidays, special events & policy changes.
:::

. . .

:::{.callout-note}
## Dummy seasonality

Use dummy variables for each season.

It can be added to models as a regressor with `season()`.
:::

## Some useful predictors

:::{.callout-tip}
## Fourier seasonality

Fourier terms use sine and cosine harmonics to model seasonality.

It offers key advantages over dummy seasonality:

* Reduce model complexity
* Non-integer seasonality

Use `fourier(K = ???)` to add fourier seasonality with `K` harmonics to the model.
:::

# Dynamic harmonic regression

## Dynamic harmonic regression

Capture seasonality with fourier terms instead of ARIMA PDQ().

\fontsize{13}{14}\sf

**Advantages**

* all the benefits of fourier terms;
* supports multiple seasonality via multiple fourier terms;
* capture remaining dynamics with a simple ARMA model.

**Disadvantages**

* seasonality cannot change over time.

## Eating-out expenditure
\fontsize{8}{9}\sf

```{r cafe, echo=TRUE, fig.height=2.3, fig.width=8}
aus_cafe <- aus_retail |>
  filter(
    Industry == "Cafes, restaurants and takeaway food services",
    year(Month) %in% 2004:2018
  ) |>
  summarise(Turnover = sum(Turnover))
aus_cafe |> autoplot(Turnover)
```

## Eating-out expenditure

\fontsize{9}{9}\sf

```{r cafefit, dependson='cafe', fig.height=5, echo=TRUE, results='hide'}
fit <- aus_cafe |> model(
  `K = 1` = ARIMA(log(Turnover) ~ fourier(K = 1) + PDQ(0, 0, 0)),
  `K = 2` = ARIMA(log(Turnover) ~ fourier(K = 2) + PDQ(0, 0, 0)),
  `K = 3` = ARIMA(log(Turnover) ~ fourier(K = 3) + PDQ(0, 0, 0)),
  `K = 4` = ARIMA(log(Turnover) ~ fourier(K = 4) + PDQ(0, 0, 0)),
  `K = 5` = ARIMA(log(Turnover) ~ fourier(K = 5) + PDQ(0, 0, 0)),
  `K = 6` = ARIMA(log(Turnover) ~ fourier(K = 6) + PDQ(0, 0, 0))
)
glance(fit)
```
```{r, echo = FALSE}
glance(fit) |>
  select(.model, sigma2, log_lik, AIC, AICc, BIC) |>
  knitr::kable()
```

## Eating-out expenditure

```{r, include=FALSE}
cafe_plot <- function(...) {
  fit |>
    select(...) |>
    forecast() |>
    autoplot(aus_cafe) +
    labs(title = sprintf("Log transformed %s, fourier(K = %s)", model_sum(select(fit, ...)[[1]][[1]]), deparse(..1))) +
    geom_label(
      aes(x = yearmonth("2007 Jan"), y = 4250, label = paste0("AICc = ", format(AICc))),
      data = glance(select(fit, ...))
    ) +
    geom_line(aes(y = .fitted), colour = "red", augment(select(fit, ...))) +
    ylim(c(1500, 5100))
}
```

```{r cafe1, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 1")
```

## Eating-out expenditure

```{r cafe2, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 2")
```

## Eating-out expenditure

```{r cafe3, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 3")
```

## Eating-out expenditure

```{r cafe4, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 4")
```

## Eating-out expenditure

```{r cafe5, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 5")
```

## Eating-out expenditure

```{r cafe6, dependson='cafe', fig.height=5, echo=FALSE}
cafe_plot("K = 6")
```

# Lab Session 16
## Lab Session 16

Produce forecasts of preschool and school education jobs from the ABS payroll data (`payroll_education`).

```{r}
#| results: hide
payroll_education |> 
  filter(Industry == "Preschool and School Education")
```

1. Estimate a TSLM model with appropriate regression terms (trend, fourier harmonics, ...)
2. Produce and visualise forecasts from this model
3. Perform residual diagnostic checks on the model
4. Instead use dynamic harmonic regression
5. Do the residuals and forecasts look better?

# Forecasting with regressors

## Forecasting with regressors

:::{.callout-note}
## Additional regressors

Using additional information from other variables is a great way to enhance your time series model.

Add them the the formula just like `lm()`.
:::

Additional regressors in forecasting models can make it harder to produce forecasts. Why?

## Forecasting with regressors

:::{.callout-important}
## Future values

Future regressor values need to be given for forecasting.
:::

. . .

**Advantages**

* Future values could be known in advance.
* Forecasts under different scenarios can be compared.

**Disadvantages**

* Unknown future values also need forecasting.
* Forecasts ignore the uncertainty in predictors.


## Lagged predictors

Sometimes a change in $x_t$ does not affect $y_t$ instantaneously

\begin{block}{}
\begin{itemize}
  \item $y_t=$ sales, $x_t=$ advertising.
  \item $y_t=$ stream flow, $x_t=$ rainfall.
  \item $y_t=$ size of herd, $x_t=$ breeding stock.
\end{itemize}
\end{block}
\pause

  * These are dynamic systems with input ($x_t$) and output $(y_t)$.
  * $x_t$ is often a leading indicator.
  * There can be multiple predictors.

## Lagged predictors

The model include present and past values of predictor: $x_t,x_{t-1},x_{t-2},\dots.$
\begin{block}{}
\centerline{$
y_t = a + \nu_0x_t + \nu_1x_{t-1} + \dots + \nu_kx_{t-k} + \eta_t$}
\end{block}
where $\eta_t$ is an ARIMA process.\pause

  * $x$ can influence $y$, but $y$ is not allowed to influence $x$.


Use `lag()` on model regressors to lag them.

## Daily electricity demand
\fontsize{12}{13}\sf

Model daily electricity demand as a function of temperature using quadratic regression with ARMA errors.

\fontsize{8}{9}\sf

```{r, echo=TRUE, fig.height=2.7}
vic_elec_daily |>
  ggplot(aes(x = Temperature, y = Demand, colour = Day_Type)) +
  geom_point() +
  labs(x = "Maximum temperature", y = "Electricity demand (GW)")
```

## Daily electricity demand
\fontsize{8}{9}\sf

```{r, echo=TRUE, fig.height=3.2}
vic_elec_daily |>
  pivot_longer(c(Demand, Temperature)) |>
  ggplot(aes(x = Date, y = value)) +
  geom_line() +
  facet_grid(vars(name), scales = "free_y")
```

## Daily electricity demand
\fontsize{8}{9}\sf

```{r dailymodel, echo=TRUE}
fit <- vic_elec_daily |>
  model(fit = ARIMA(Demand ~ Temperature + I(Temperature^2) +
    (Day_Type == "Weekday")))
report(fit)
```

## Daily electricity demand

```{r, echo=TRUE, dependson='dailymodel'}
augment(fit) |>
  gg_tsdisplay(.resid, plot_type = "histogram")
```

## Daily electricity demand

\fontsize{10}{10}\sf
```{r, echo=TRUE, dependson='dailymodel'}
#| error: true
fit |> 
  forecast(h = 14)
```

\fontsize{14}{16}\sf
::: {.callout-important}
## More information needed

Our model depends on `Temperature` and `Day_Type`.

To produce forecasts, we need to also provide future values for these variables.
:::

## Daily electricity demand
\fontsize{10}{10}\sf

```{r}
#| echo: false
options(width = 100)
```


```{r, echo=TRUE, dependson='dailymodel'}
# Forecast one day ahead.
vic_next_day <- new_data(vic_elec_daily, 1) |>
  mutate(Temperature = 26, Day_Type = "Holiday")
forecast(fit, vic_next_day)
```

```{r}
#| echo: false
options(width = 80)
```

## Daily electricity demand

```{r, echo=TRUE}
# Forecast two weeks ahead.
vic_elec_future <- new_data(vic_elec_daily, 14) |>
  mutate(
    Temperature = 26,
    Holiday = c(TRUE, rep(FALSE, 13)),
    Day_Type = case_when(
      Holiday ~ "Holiday",
      wday(Date) %in% 2:6 ~ "Weekday",
      TRUE ~ "Weekend"
    )
  )
```

\fontsize{12}{12}\sf

::: {.callout-tip}
## Scenario forecasting

Instead of forecasting most-likely values for regressors, it can be worthwhile forecasting worst-case scenarios to adequately prepare.
:::

## Daily electricity demand
\fontsize{8}{9}\sf

```{r, echo = TRUE, dependson='dailymodel'}
forecast(fit, vic_elec_future) |>
  autoplot(vic_elec_daily) + labs(y = "Electricity demand (GW)")
```

## Scenarios with policy decisions

Consider the total school students aged 15-19 in Australia.

```{r}
#| fig-height: 2.8
working_age_school_students <- student_labour |> 
  filter(attendance == "Attending school (aged 15-19 years)") |> 
  summarise(persons = sum(persons))
working_age_school_students |> autoplot(persons)
```



## Scenarios with policy decisions

Without capturing the policy change, the forecasts are biased.

```{r}
#| fig-height: 2.9
working_age_school_students |> 
  model(ARIMA(persons ~ fourier(K = 3))) |> 
  forecast(h = "10 years") |> 
  autoplot(working_age_school_students)
```

## Scenarios with policy decisions

Add dummy variable for the change in 2013 that interacts with the seasonality.

\fontsize{10}{10}\sf
```{r}
fit_policy <- working_age_school_students |> 
  mutate(new_policy = month >= yearmonth("2013 Jan")) |> 
  model(ARIMA(persons ~ new_policy*fourier(K = 3)))
report(fit_policy)
```

## Scenarios with policy decisions

The policy is expected to continue into the future.

```{r}
#| fig-height: 2.6
future_policy <- new_data(working_age_school_students, 120) |> 
  mutate(new_policy = TRUE)
fit_policy |> 
  forecast(new_data(working_age_school_students, 120) |> mutate(new_policy = TRUE)) |> 
  autoplot(working_age_school_students)
```


# Lab Session 17
## Lab Session 17

What if the 2013 policy was later reverted, what would you expect the forecasts to be?

1. Produce forecasts from a scenario in which this policy was reverted in 2030. 

   Hint: Use `new_data()` to create the future time points, and `mutate()` a date comparison to create the future dummy variable values.

2. Visualise the forecasts, are they realistic?

## Forecasting unkown scenarios

\full{tertiary-caps}

## Forecasting unkown scenarios

```{r}
#| fig-height: 3
student_labour |> 
  filter(attendance == "Attending tertiary educational institution full-time") |> 
  summarise(persons = sum(persons)) |> 
  autoplot(persons)
```

## Forecasting unkown scenarios

:::{.callout-tip}
## How would we forecast something without history?

* Judgemental forecasting with expert opinions
* Incorporate limits into the model 

  (will these limits be met by demand?)
* Forecast more disaggregated data separately
:::
