---
title: "Time Series Analysis & Forecasting Using R"
subtitle: "11. Multivariate modelling"
format:
  beamer:
    pdf-engine: pdflatex
    aspectratio: 169
    fontsize: "14pt,t"
    section-titles: false
    knitr:
      opts_chunk:
        dev: "cairo_pdf"
    fig-width: 7.5
    fig-height: 3.5
    include-in-header: header.tex
    keep-tex: false
---

## Outline

\vspace*{0.7cm}\tableofcontents

```{r}
#| label: setup
#| include: false
#| cache: false
source("setup.R")
```

# Multivariate modelling

## Multivariate modelling

Multivariate models jointly describes the dynamic interrelationships between two or more measured variables. 

They are particularly useful for:

* understanding how variables influence each other over time
* analysing causality and cointegration
* investigating the effect of shocks in the system.


<!-- ## School groups -->

<!-- ```{r} -->
<!-- #| eval: false -->
<!-- student_affiliation <- students |>  -->
<!--   group_by(`Affiliation (Gov/Cath/Ind)`) |>  -->
<!--   summarise(Count = sum(`All Full-time and Part-time Student count`)) |>  -->
<!--   pivot_wider(names_from = `Affiliation (Gov/Cath/Ind)`, values_from = Count) -->
<!-- student_affiliation |>  -->
<!--   model(VARIMA(vars(Catholic, Government, Independent) ~ AR(3))) |>  -->
<!--   forecast() |>  -->
<!--   autoplot(student_affiliation) -->
<!-- ``` -->

# Vector Autoregression (VAR)

## Autoregression (AR)

Recall the AR($p$) model for a **univariate** time series $y_t$ is:

$$
  y_t = a_1 y_{t-1} + a_2 y_{t-2} + \dots + a_p y_{t-p} + \varepsilon_t
$$

\fontsize{4}{14}\sf

where:

- $y_t$ is the time series at time $t$,
- $a_1, a_2, \dots, a_p$ are the coefficients for the autoregressive lags,
- $p$ is the order of the AR process,
- $\varepsilon_t$ is the white noise error term at time $t$.

## Endogeneity

Endogeneity occurs when an explanatory variable is correlated with the error term in a model. This can cause a 'feedback loop' in the model estimation which:

* Leads to biased and inconsistent estimates.
* Compromises hypothesis testing and forecasting.

. . .

Common Causes of endogeneity in time series include:

* Simultaneity: Variables with bidirectional contemporaneous effects.
* Omitted Variables: Missing relevant variables.
* Measurement Errors: Inaccuracy in data collection.

## Cross correlations

The Cross-Correlation Function (CCF) measures the correlation between two time series at different time lags.

It indicates the relationship between two variables over time.

```{r}
#| fig-height: 2
global_economy |> 
  filter(Country == "Australia") |> 
  CCF(Imports, Exports) |> 
  autoplot()
```



## Vector Autoregression (VAR)

The general form of a VAR model with $k$ time series variables $Y_t = (y_{1t}, y_{2t}, \dots, y_{kt})'$ is:

$$
  Y_t = A_1 Y_{t-1} + A_2 Y_{t-2} + \dots + A_p Y_{t-p} + \varepsilon_t
$$

where:

- $Y_t$ is a vector of endogenous variables at time $t$,
- $A_i$ are coefficient matrices (each of size $k \times k$),
- $p$ is the lag order,
- $\varepsilon_t$ is a vector of error terms (mean zero, covariance $\Sigma$).


## Vector Autoregression (VAR)

In matrix form, the VAR($p$) model is written as:
  
$$
  \Phi(B) Y_t = \varepsilon_t
$$

where:

- $Y_t$ is a $k \times 1$ vector of endogenous variables,
- $\Phi(B)$ is a matrix polynomial of AR coefficients,
- $\varepsilon_t$ is a $k \times 1$ vector of error terms (white noise).

<!-- About 20 minutes -->

## Vector Autoregression (VAR)

VAR (Vector Autoregression) models handle endogeneity by treating all variables in the system as endogenous.

. . .

\fontsize{11}{12}\sf
```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports)))
```

\fontsize{16}{16}\sf

Use `VAR()` to specify a model, specifying all response variables in the model with `vars()`.


## Vector Autoregression (VAR)

\fontsize{10}{10}\sf
```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports))) |> 
  report()
```

## Vector Autoregression (VAR)

Forecasts from VAR models are multivariate normal.


\fontsize{10}{10}\sf
```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports))) |> 
  forecast(h = "10 years")
```


## Vector Autoregression (VAR)

Plotting multivariate forecasts shows intervals from marginal forecast distributions.

```{r}
#| fig-height: 2
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports))) |> 
  forecast(h = "10 years") |> 
  autoplot(global_economy)
```


## Impulse Response Functions

Impulse Response Functions (IRFs) reveal the response of one variable to shocks in another.

\fontsize{10}{10}\sf
```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports))) |> 
  IRF(h = 10, impulse = "Imports")
```


## Impulse Response Functions

They can be plotted using `gg_irf()`

```{r}
#| fig-height: 2.5
global_economy |> 
  filter(Country == "Australia") |> 
  model(var = VAR(vars(Imports, Exports))) |> 
  IRF(h = 10, impulse = "Imports") |> 
  gg_irf()
```


# Vector Error Correction Models (VECM)

## Cointegration

::: {.callout-note}
## Definition

Cointegration is when two or more non-stationary time series, each integrated of the same order, are linked by a long-term equilibrium relationship.
:::

For example: If $x$ and $y$ are non-stationary ($I(1)$), and a linear combination of them is stationary ($I(0)$), then $x$ and $y$ are cointegrated.

## Cointegration

Is Australian imports and exports cointegrated?

```{r}
#| fig-height: 3
global_economy |> 
  filter(Country == "Australia") |> 
  autoplot(vars(Imports, Exports)) 
```


## Cointegration

Yes, both are non-stationary but their difference is stationary.

```{r}
#| fig-height: 3
global_economy |> 
  filter(Country == "Australia") |> 
  autoplot(Imports - Exports) 
```

## The Johansen test

The Johansen test helps to determine how many long-term equilibrium (cointegrating) relationships exist between the variables.

\fontsize{10}{10}\sf
```{r}
aus_economy <- global_economy |>
  filter(Country == "Australia")
aus_economy |>
  with(cointegration_johansen(cbind(Imports, Exports)))
```


## Vector Error Correction Models (VECM)

The VECM is used when variables are cointegrated. 

The form of a VECM for $Y_t$ is:

$$
  \Delta Y_t = \Pi Y_{t-1} + \sum_{i=1}^{p-1} \Gamma_i \Delta Y_{t-i} + \varepsilon_t
$$

where:

- $\Delta Y_t = Y_t - Y_{t-1}$ is the first difference of $Y_t$,
- $\Pi$ is the cointegration matrix (long-run coefficients)
- $\Gamma_i$ are short-run adjustment coefficients,
- $\varepsilon_t$ is the error term.

## Estimating a VECM

\fontsize{10}{10}\sf
```{r vecm}
global_economy |> 
  filter(Country == "Australia") |> 
  model(vecm = VECM(vars(Imports, Exports) ~ 1 + AR(p = 1), r = 1)) |> 
  report()
```

\fontsize{16}{16}\sf

Use `VECM()` to specify a model, with the number of cointegrating relationships for `r`.

## Forecasting a VECM

\fontsize{11}{12}\sf
```{r vecm-fc}
#| fig-height: 3.5
global_economy |> 
  filter(Country == "Australia") |> 
  model(vecm = VECM(vars(Imports, Exports) ~ 1 + AR(p = 1), r = 1)) |> 
  forecast(h = "10 years") |> 
  autoplot(global_economy)
```

# VARIMA Models

## VARIMA Models

The VARIMA model extends an ARIMA model to capture relationships between multiple time series.
  
$$
  \Phi(B) \Delta^d Y_t = \Theta(B) \varepsilon_t
$$

where:

- $\Phi(B)$ is the matrix polynomial for the AR part,
- $\Delta^d Y_t$ is the differenced series,
- $\Theta(B)$ is the matrix polynomial for the MA part,
- $\varepsilon_t$ is the error term. 

## VARIMA Models

VARIMA models are useful for modelling multiple related non-stationary time series which are **not** cointegrated.

. . .

::: {.callout-tip}
## Handling non-stationarity

Much like ARIMA, we use transformations and differences to make non-stationary variables stationary.

:::

## Identifying VARIMA models

VARIMA models can be statistically difficult to estimate.

This is because their coefficients aren't always uniquely identified.

. . .

::: {.callout-important}

## Constraints for identification

We must force some coefficients to zero (usually MA coefficients) to ensure identification.

Identification of VARIMA models is often achieved with estimation using Kronecker indices or scalar components.

:::

## Estimating VARIMA models

Much like `ARIMA()`, we use `VARIMA()` and `pdq()` to specify a VARIMA model.

\fontsize{10}{10}\sf
```{r}
aus_economy |> 
  filter(!is.na(Growth)) |> 
  model(varima = VARIMA(vars(Growth, Imports))) |> 
  report()
```


## Forecasting VARIMA models

```{r}
#| fig-height: 3
aus_economy |> 
  filter(!is.na(Growth)) |> 
  model(varima = VARIMA(vars(Growth, Imports))) |> 
  forecast(h = "10 years") |> 
  autoplot(aus_economy)
```

# Lab Session 18

## Lab Session 18

Consider multivariate modelling of education staff affiliation.

```{r}
staff_affiliation <- staff |> 
  group_by(`Affiliation 2`) |> 
  summarise(Count = sum(`In-School Staff Count`)) |> 
  pivot_wider(names_from = `Affiliation 2`, values_from = Count)
```

1. Which model (VAR, VECM, or VARIMA) is most appropriate for this data?

2. Estimate a suitable multivariate model for this relationship.

```{r}
#| include: false
staff_affiliation |> 
  model(VECM(vars(Catholic, Government, Independent) ~ AR(1), r = 2))
```


3. Compute and visualise the impulse response functions.

```{r}
#| include: false
staff_affiliation |> 
  model(VECM(vars(Catholic, Government, Independent) ~ AR(1), r = 2)) |> 
  IRF(impulse = "Independent") |> 
  gg_irf()
```

4. Produce and visualise forecasts from the model.

```{r}
#| include: false
staff_affiliation |> 
  model(VECM(vars(Catholic, Government, Independent) ~ AR(1), r = 2)) |> 
  forecast(h = "10 years") |> 
  autoplot(staff_affiliation)
```

# Forecast reconciliation

# Hierarchical and grouped time series

## Australian tourism
\fontsize{9}{10}\sf

```{r tourism}
tourism
```

\begin{textblock}{7}(8.5,1.5)\fontsize{10}{11}\sf
\begin{block}{}
  \begin{itemize}\itemsep=0cm\parskip=0cm
    \item Quarterly data on visitor nights, 1998:Q1 -- 2017:Q4
    \item From: \textit{National Visitor Survey}, based on annual interviews of 120,000 Australians aged 15+, collected by Tourism Research Australia.
    \item Split by 8 states and 76 regions
    \item Split by purpose of travel
      \begin{itemize}\fontsize{10}{11}\sf
        \item Holiday
        \item Visiting friends and relatives (VFR)
        \item Business
        \item Other
      \end{itemize}
    \item 304 bottom-level series
  \end{itemize}
\end{block}
\end{textblock}

## Hierarchical time series
\fontsize{13}{14}\sf

A \alert{\textbf{hierarchical time series}} is a collection of several time series that are linked together in a hierarchical structure.

\begin{minipage}{9.6cm}
\begin{block}{}
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,fill=red!15]
\tikzstyle[level distance=.1cm]
\tikzstyle[sibling distance=7cm]
\tikzstyle{level 1}=[sibling distance=33mm,set style={{every node}+=[fill=blue!15]}]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AA}}
   child {node {AB}}
   child {node {AC}}
 }
 child {node {B}
   child {node {BA}}
   child {node {BB}}
   child {node {BC}}
 }
 child {node {C}
   child {node {CA}}
   child {node {CB}}
   child {node {CC}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\pause\alert{Examples}\vspace*{-0.2cm}

 * PBS sales by ATC groups
 * Tourism demand by states, regions

## Grouped time series
\fontsize{13}{14}\sf

A \alert{\textbf{grouped time series}} is a collection of time series that can be grouped together in a number of non-hierarchical ways.

\begin{minipage}{9.2cm}
\begin{block}{}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {A}
   child {node {AX}}
   child {node {AY}}
 }
 child {node {B}
   child {node {BX}}
   child {node {BY}}
 };
\end{tikzpicture}\hspace*{1cm}
\begin{tikzpicture}[level distance=1.5cm]
\tikzstyle{every node}=[ellipse,draw,inner sep=0.2pt,outer sep=0pt, fill=red!15]
\tikzstyle{level 1}=[sibling distance=23mm,set style={{every node}+=[fill=blue!15]},level distance=1cm]
\tikzstyle{level 2}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=yellow]}, level distance=0.9cm]
\node{Total}[edge from parent fork down]
 child {node {X}
   child {node {AX}}
   child {node {BX}}
 }
 child {node {Y}
   child {node {AY}}
   child {node {BY}}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\pause\alert{Examples}

 * Tourism by state and purpose of travel
 * Retail sales by product groups/sub groups, and by countries/regions

## Creating aggregates
\fontsize{8}{8}\sf

```{r tourism_aggregate}
tourism |>
  aggregate_key(Purpose * (State / Region), Trips = sum(Trips)) |>
  arrange(Quarter) |> 
  print(n=20)
```

## Creating aggregates
\fontsize{13}{15}\sf

 * Similar to `summarise()` but using the key structure
 * A grouped structure is specified using `grp1 * grp2`
 * A nested structure is specified via `parent / child`.
 * Groups and nesting can be mixed:

    ```r
    (country/region/city) * (brand/product)
    ```

 * All possible aggregates are produced.
 * These are useful when forecasting at different levels of aggregation.

## Forecast reconciliation: the problem
\fontsize{13}{14}\sf

\begin{alertblock}{}
\begin{enumerate}\tightlist
 \item How to forecast time series at all nodes such that the forecasts add up in the same way as the original data?
 \item Can we exploit relationships between the series to improve the forecasts?
\end{enumerate}
\end{alertblock}\pause

### Forecast reconciliation: the solution

1. Forecast all series at all levels of aggregation using an automatic forecasting algorithm.\newline (e.g., `ETS`, `ARIMA`, ...)
2. Reconcile the resulting forecasts so they add up correctly using least squares optimization (i.e., find closest reconciled forecasts to the original forecasts).
3. This is available using `reconcile()`.

## Forecast reconciliation
\fontsize{9}{10}\sf

```{r tourismets_reconciled, message=FALSE}
tourism |>
  aggregate_key(Purpose * (State / Region), Trips = sum(Trips)) |>
  model(ets = ETS(Trips)) |>
  reconcile(ets_adjusted = min_trace(ets)) |>
  forecast(h = 2)
```

## Hierarchical and grouped time series

Every collection of time series with aggregation constraints can be written as
\begin{block}{}
\centerline{$\by_{t}=\bS\bm{b}_{t}$}
\end{block}
where

 * $\by_t$ is a vector of all series at time $t$
 * $\bm{b}_t$ is a vector of the most disaggregated series at time $t$
 * $\bS$ is a ``summing matrix'' containing the aggregation constraints.

## Hierarchical time series

\begin{minipage}{4cm}\vspace*{0.2cm}
\begin{block}{}\centering
\begin{tikzpicture}
\tikzstyle{every node}=[ellipse,draw,fill=red!15,inner sep=2pt]
\tikzstyle[level distance=.3cm]
\tikzstyle[sibling distance=12cm]
\tikzstyle{level 1}=[sibling distance=10mm,font=\small,set style={{every node}+=[fill=blue!15]}]
\node{Total}[edge from parent fork down]
 child {node {A}
 }
 child {node {B}
 }
 child {node {C}
 };
\end{tikzpicture}
\end{block}
\end{minipage}

\only<2->{\begin{textblock}{6.3}(6,1)\small
\begin{itemize}\itemsep=0cm\parskip=0cm
\item[$ y_{t}: $] observed aggregate of all series at time
$t$.
\item[$ y_{X,t}: $] observation on series $X$ at time $t$.
\item[$ \bm{b}_{t}: $] vector of all series at bottom level
in time $t$.
\end{itemize}
\end{textblock}}\vspace*{0.6cm}
\only<3->{
$\bY_{t}= \begin{pmatrix}
  y_{t}\\
  y_{A,t}\\
  y_{B,t}\\
  y_{C,t}
  \end{pmatrix} = \only<3>{\hspace*{0.01cm}\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}\only<4->{{\color{blue}\underbrace{\begin{pmatrix}
                1 & 1 & 1 \\
                1 & 0 & 0 \\
                0 & 1 & 0\\
                0 & 0 & 1
                \end{pmatrix}}_{\bS}}}\only<3>{\hspace*{0.08cm}}\only<3>{\hspace*{-0.1cm}\begin{pmatrix}y_{A,t}\\y_{B,t}\\y_{C,t}\end{pmatrix}}\rule{0cm}{1.6cm}
                \only<4->{\hspace*{0.08cm}{\color{red}\underbrace{\begin{pmatrix}y_{A,t}\\y_{B,t}\\y_{C,t}\end{pmatrix}}_{\bm{b}_{t}}}}$}

\vspace*{-0.8cm}

\only<4>{\hspace*{8cm}\colorbox[RGB]{210,210,210}{$\bY_{t}=\color{blue}\bS\color{red}\bm{b}_{t}$}}

\vspace*{10cm}

## Forecasting notation

Let $\hat{\by}_n(h)$ be vector of initial $h$-step forecasts, made at time $n$, stacked in same order as $\by_t$. \pause\newline  (In general, they will not ``add up''.)\pause

\begin{block}{}
Reconciled forecasts must be of the form:
\centerline{$\tilde{\by}_{n}(h)=\bS\bm{G}\hat{\by}_{n}(h)$}
for some matrix $\bm{G}$.
\end{block}\pause

 * $\bm{G}$ extracts and combines base forecasts $\hat{\by}_{n}(h)$ to get bottom-level forecasts.
 * $\bS$ adds them up

# Forecast combination techniques

## Simple combination forecasts

There are several ways to adjust forecasts to be coherent.

* `bottom_up()`

  Simply aggregate the most disaggregated forecasts

* `top_down()`

  Disaggregate the top level forecast
  
* `middle_out()`

  Find a middle level of disaggregation, applying both bottom up and top down techniques.

## Optimal combination forecasts
\fontsize{13}{14}\sf

\begin{alertblock}{Main result}
The best (minimum sum of variances) unbiased forecasts are obtained when
$\bm{G} = (\bS'\bW^{-1}_{h}\bS)^{-1}\bS'\bW^{-1}_{h}$,
where $\bW_h$ is the $h$-step base forecast error covariance matrix.
\end{alertblock}

\pause

\begin{block}{}
\centerline{$\displaystyle\textcolor{red}{\tilde{\by}_{n}(h)}
=\bS(\bS'\bW^{-1}_{h}\bS)^{-1}\bS'\bW^{-1}_{h}\textcolor{blue}{\hat{\by}_{n}(h)}$}
\end{block}\vspace*{-0.2cm}

\alert{\textbf{Problem:}} $\bW_h$ hard to estimate, especially for $h>1$.
\vspace*{-0.1cm}

\alert{Solutions:}\vspace*{-0.4cm}

 * Ignore $\bW_h$ (OLS) [`min_trace(method='ols')`]
 * Assume $\bW_h = k_h\bW_1$ is diagonal (WLS) [`min_trace(method='wls')`]
 * Assume $\bW_h = k_h\bW_1$ and estimate it (GLS) [`min_trace(method='shrink')` (the default)]

## Features
\fontsize{15}{17}\sf

 * Covariates can be included in initial forecasts.
 * Adjustments can be made to initial forecasts at any level.
 * Very simple and flexible method. Can work with *any* hierarchical or grouped time series.
 * Conceptually easy to implement: regression of base forecasts on structure matrix.

## Example: Australian tourism
\fontsize{12}{13}\sf

```{r fctourism}
tourism_agg <- tourism |>
  aggregate_key(Purpose * (State / Region),
    Trips = sum(Trips)
  )
fc <- tourism_agg |>
  filter(Quarter < yearquarter("2016 Q1")) |> 
  model(ets = ETS(Trips)) |>
  reconcile(ets_adjusted = min_trace(ets)) |>
  forecast(h = "2 years")
```

## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism2, dependson='fctourism'}
fc |>
  filter(is_aggregated(Purpose), Region == "Sydney") |>
  autoplot(tourism_agg, level = 95)
```


## Example: Australian tourism
\fontsize{10}{11}\sf

```{r fctourism3, dependson='fctourism'}
fc |>
  accuracy(tourism_agg) |> 
  group_by(.model) |> 
  summarise(across(where(is.numeric), mean))
```

# Lab Session 19

## Lab Session 19

Produce coherent forecasts of the total number of students.

1. Produce aggregates of `students` by `State/Territory`, `Affiliation (Gov/Cath/Ind)` and `School Level`.

2. Estimate automatic ETS models on data before 2020.

3. Use optimal forecast reconciliation for these models.

4. Produce and plot 4 years of coherent and base forecasts.

5. Evaluate the test-set accuracy of these forecasts Are the coherent forecasts more accurate?

```{r}
#| include: false
#| eval: false
students_agg <- students |> 
  aggregate_key(
    `State/Territory` * `Affiliation (Gov/Cath/Ind)` * `School Level`,
    Students = sum(`All Full-time and Part-time Student count`)
  )
students_agg |> 
  filter(Year < 2020) |> 
  model(ets = ETS(Students)) |> 
  reconcile(min_trace(ets)) |> 
  forecast(h = 4) |> 
  accuracy(students_agg) |> 
  group_by(.model) |> 
  summarise(across(where(is.numeric), mean))
```


